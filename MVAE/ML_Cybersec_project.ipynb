{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWQPlsK9M8x6",
        "outputId": "c0873f03-6d2e-4ca9-e88e-587e5c8bdce0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 6.3 kB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.11.23 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IaQCrdXqLEGW"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow\n",
        "\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "# from keras import objectives\n",
        "from keras.layers import Dropout, Reshape, Concatenate, Flatten, Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, accuracy_score, precision_recall_fscore_support, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MVAE(object):\n",
        "\n",
        "\n",
        "    def create(self, max_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix):\n",
        "\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.fnd = None\n",
        "        self.autoencoder = None\n",
        "        self.embedding_matrix = embed_matrix\n",
        "        self.vocab_size = self.embedding_matrix.shape[0]\n",
        "        self.max_length = max_length\n",
        "        self.latent_dim = latent_dim\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.fnd_lambda = fnd_lambda\n",
        "        self.image_embed_size = image_embed_size\n",
        "\n",
        "        input_txt = Input(shape=(self.max_length,), name='input_txt')\n",
        "        input_img = Input((image_embed_size, ), name='input_img') \n",
        "\n",
        "        vae_ce_loss, vae_mse_loss, encoded = self._build_encoder(input_txt, input_img)\n",
        "        self.encoder = Model(inputs=[input_txt, input_img], outputs=encoded)\n",
        "\n",
        "        encoded_input = Input(shape=(self.latent_dim,))\n",
        "        predicted_outcome = self._build_fnd(encoded_input)\n",
        "        self.fnd = Model(encoded_input, predicted_outcome)\n",
        "\n",
        "        decoded_txt, decoded_img = self._build_decoder(encoded_input)\n",
        "        self.decoder = Model(encoded_input, [decoded_txt, decoded_img])\n",
        "\n",
        "        decoder_output = self._build_decoder(encoded)\n",
        "\n",
        "        self.autoencoder = Model(inputs=[input_txt, input_img], outputs=[decoder_output[0], decoder_output[1], self._build_fnd(encoded)])\n",
        "        self.autoencoder.compile(optimizer=Adam(1e-5),\n",
        "                                 loss=['sparse_categorical_crossentropy', vae_mse_loss, 'binary_crossentropy'],\n",
        "                                 metrics=['accuracy'])\n",
        "        self.get_features = K.function([input_txt, input_img], [encoded])\n",
        "        print(self.autoencoder.summary())\n",
        "\n",
        "\n",
        "    def _build_encoder(self, input_txt, input_img, latent_dim=64):\n",
        " \n",
        "        txt_embed = Embedding(self.vocab_size, 32, input_length=self.max_length, name='txt_embed', trainable=False, weights=[self.embedding_matrix])(input_txt)\n",
        "        lstm_txt_1 = Bidirectional(LSTM(32, return_sequences=True, name='lstm_txt_1', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda)), merge_mode='concat')(txt_embed)\n",
        "        lstm_txt_2 = Bidirectional(LSTM(32, return_sequences=False, name='lstm_txt_2', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda)), merge_mode='concat')(lstm_txt_1)\n",
        "        fc_txt = Dense(32, activation='tanh', name='dense_txt', kernel_regularizer=regularizers.l2(self.reg_lambda))(lstm_txt_2)\n",
        "\n",
        "        fc_img_1 = Dense(1024, name='fc_img_1', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(input_img)\n",
        "        fc_img_2 = Dense(32, name='fc_img_2', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(fc_img_1)\n",
        "\n",
        "        h = Concatenate(axis=-1, name='concat')([fc_txt, fc_img_2])\n",
        "        h = Dense(64, name='shared', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(h)\n",
        "\n",
        "        def sampling(args):\n",
        "            z_mean_, z_log_var_ = args\n",
        "            batch_size = K.shape(z_mean_)[0]\n",
        "            epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=0.01)\n",
        "            return z_mean_ + K.exp(0.5 * z_log_var_) * epsilon\n",
        "\n",
        "        z_mean = Dense(latent_dim, name='z_mean', activation='linear')(h)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var', activation='linear')(h)\n",
        "\n",
        "        def vae_mse_loss(x, x_decoded_mean):\n",
        "            mse_loss = keras.losses.mean_squared_error(x, x_decoded_mean)\n",
        "            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "            return mse_loss + kl_loss\n",
        "        \n",
        "        def vae_ce_loss(x, x_decoded_mean):\n",
        "            x = K.flatten(x)\n",
        "            x_decoded_mean = K.flatten(x_decoded_mean)\n",
        "            xent_loss = keras.losses.binary_crossentropy(x, x_decoded_mean)\n",
        "            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "            return xent_loss + kl_loss\n",
        "\n",
        "        return (vae_ce_loss, vae_mse_loss, Lambda(sampling, output_shape=(latent_dim,), name='lambda')([z_mean, z_log_var]))\n",
        "\n",
        "\n",
        "    def _build_decoder(self, encoded):\n",
        "\n",
        "        dec_fc_txt = Dense(32, name='dec_fc_txt', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(encoded)\n",
        "        repeated_context = RepeatVector(self.max_length)(dec_fc_txt)\n",
        "        dec_lstm_txt_1 = LSTM(32, return_sequences=True, activation='tanh', name='dec_lstm_txt_1', kernel_regularizer=regularizers.l2(self.reg_lambda))(repeated_context)\n",
        "        dec_lstm_txt_2 = LSTM(32, return_sequences=True, activation='tanh', name='dec_lstm_txt_2', kernel_regularizer=regularizers.l2(self.reg_lambda))(dec_lstm_txt_1)\n",
        "        decoded_txt = TimeDistributed(Dense(self.vocab_size, activation='softmax'), name='decoded_txt')(dec_lstm_txt_2)\n",
        "\n",
        "        dec_fc_img_1 = Dense(32, name='dec_fc_img_1', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(encoded)\n",
        "        dec_fc_img_2 = Dense(1024, name='dec_fc_img_2', activation='tanh', kernel_regularizer=regularizers.l2(self.reg_lambda))(dec_fc_img_1)\n",
        "        decoded_img = Dense(4096, name='decoded_img', activation='sigmoid')(dec_fc_img_2)\n",
        "\n",
        "        return decoded_txt, decoded_img\n",
        "\n",
        "\n",
        "    def _build_fnd(self, encoded):\n",
        "\n",
        "        h = Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(self.fnd_lambda))(encoded)\n",
        "        h = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(self.fnd_lambda))(h)\n",
        "        return Dense(1, activation='sigmoid', name='fnd_output')(h)"
      ],
      "metadata": {
        "id": "km5TbX8zOTLW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
        "\n",
        "    text = np.load('data/train_text.npy')\n",
        "    im = np.load('data/train_image_embed.npy')\n",
        "    label = np.load('data/train_label.npy')[:,1]\n",
        "    \n",
        "    test_text = np.load('data/test_text.npy')\n",
        "    test_im = np.load('data/test_image_embed.npy')\n",
        "    test_label = np.load('data/test_label.npy')[:,1]\n",
        "\n",
        "    embed_matrix = np.load('data/embedding_matrix.npy')\n",
        "    vocab_size = embed_matrix.shape[0]\n",
        "    \n",
        "    temp = np.zeros((text.shape[0], sequence_length, vocab_size))\n",
        "    temp[np.expand_dims(np.arange(text.shape[0]), axis=0).reshape(text.shape[0], 1), np.repeat(np.array([np.arange(sequence_length)]), text.shape[0], axis=0), text] = 1\n",
        "    text_one_hot = temp\n",
        "    \n",
        "    temp = np.zeros((test_text.shape[0], sequence_length, vocab_size))\n",
        "    temp[np.expand_dims(np.arange(test_text.shape[0]), axis=0).reshape(test_text.shape[0], 1), np.repeat(np.array([np.arange(sequence_length)]), test_text.shape[0], axis=0), test_text] = 1\n",
        "    test_text_one_hot = temp\n",
        "    \n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    if not os.path.exists(path+'/tb'):\n",
        "        os.makedirs(path+'/tb')\n",
        "    if not os.path.exists(path+'/weights'):\n",
        "        os.makedirs(path+'/weights')\n",
        "    tensorboard = TensorBoard(log_dir=path+'/tb', write_graph=True, write_images=True)\n",
        "    checkpoint = ModelCheckpoint(path+'/weights/{epoch:02d}.hdf5', monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='fnd_output_loss', factor=0.2, patience=6, min_lr=1e-7)\n",
        "\n",
        "    model = MVAE()\n",
        "    model.create(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix)\n",
        "    model.autoencoder.fit(x=[text, im], y={'decoded_txt': np.expand_dims(text, -1), 'decoded_img':im, 'fnd_output': label},\n",
        "                          batch_size=128, epochs=300, callbacks=[checkpoint, tensorboard, reduce_lr], shuffle=True,\n",
        "                          validation_data=([test_text, test_im], {'decoded_txt': np.expand_dims(test_text, -1), 'decoded_img':test_im, 'fnd_output': test_label}))"
      ],
      "metadata": {
        "id": "LuW-c63ncFBp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_features(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
        "    \n",
        "    test_text = np.load('../data/test_text.npy')\n",
        "    test_im = np.load('../data/test_image_embed.npy')\n",
        "\n",
        "    embed_matrix = np.load('../data/embedding_matrix.npy')\n",
        "    vocab_size = embed_matrix.shape[0]\n",
        "    \n",
        "    model = MVAE()\n",
        "    model.create(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix)\n",
        "    model.autoencoder.load_weights(path+'/weights/286.hdf5')\n",
        "    \n",
        "    if not os.path.exists(path+'/features'):\n",
        "        os.makedirs(path+'/features')\n",
        "\n",
        "    learnt_features = np.array([]).reshape(0, 64) \n",
        "    for i in range(test_text.shape[0]):\n",
        "        text_batch = test_text[i:i+1]\n",
        "        im_batch = test_im[i:i+1]\n",
        "        batch = model.get_features([text_batch, im_batch])[0]\n",
        "        learnt_features = np.concatenate([learnt_features, batch])\n",
        "    np.save(path+'/features/vae_fnd', learnt_features)"
      ],
      "metadata": {
        "id": "zGMRcwr5cKQD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path):\n",
        "\n",
        "    test_text = np.load('data/test_text.npy')\n",
        "    test_im = np.load('data/test_image_embed.npy')\n",
        "    test_label = np.load('data/test_label.npy')[:,1]\n",
        "\n",
        "    embed_matrix = np.load('data/embedding_matrix.npy')\n",
        "    vocab_size = embed_matrix.shape[0]\n",
        "\n",
        "    model = MVAE()\n",
        "    model.create(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, embed_matrix)\n",
        "    model.autoencoder.load_weights(path+'/weights/224.hdf5')\n",
        "    for i in range(10):\n",
        "        pred = model.autoencoder.predict([test_text, test_im])[-1]\n",
        "        pred[pred > 0.5] = 1\n",
        "        pred[pred <= 0.5] = 0\n",
        "        print(accuracy_score(test_label, pred))\n",
        "        print(precision_recall_fscore_support(test_label, pred))\n",
        "\n",
        "    pdb.set_trace()\n"
      ],
      "metadata": {
        "id": "hC_CtFEVcNLl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    train(20, 4096, 64, 0.05, 0.3, 'models/vae_fnd_0.05_0.3')\n",
        "    test(20, 4096, 64, 0.05, 0.3, 'models/vae_fnd_0.05_0.3')\n",
        "    save_features(20, 4096, 64, 0.05, 0.3, '../models/vae_fnd_0.05_0.3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "3uP-yX7RcUNC",
        "outputId": "ed9b4505-63c7-4d56-c080-8cb14493efe5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-27a124d54cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/vae_fnd_0.05_0.3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/vae_fnd_0.05_0.3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/vae_fnd_0.05_0.3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-7a1d403a38c1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sequence_length, image_embed_size, latent_dim, reg_lambda, fnd_lambda, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnd_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train_text.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train_image_embed.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train_label.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train_text.npy'"
          ]
        }
      ]
    }
  ]
}